import os
import sys
import functools
import json
import re
import pandas as pd # Tested w/ v0.24
from collections import defaultdict


# RESULT PATHS

prefix_results = functools.partial(os.path.join, config['results'])
FASTQ_DIR = prefix_results('fastq')
SAM_DIR = prefix_results('sam')
COUNTS_DIR = prefix_results('counts')
RESULTS_DIR = prefix_results('results')

#Setup for non-module software
try:
    CalculateTilingStatistic_loc = config['CalculateTilingStatistic_loc']
except:
    logger.info("Cannot find software locations in config. Defaulting to rjhryan_turbo locations")
    CalculateTilingStatistic_loc = '/nfs/turbo/path-rjhryan-turbo/software/crispri_lander/region_scoring/src/CRISPRScreen/CalculateTilingStatistic.R'

SCRIPTS_DIR = os.path.join(os.getcwd(), 'scripts')

# Load Modules

software_strings = [
    "module load Bioinformatics ;",
    "module load cutadapt/1.18 ;",
    "module load bowtie/1.2.2 ;",
    "module load python3.7-anaconda/2019.07 ;", #Python3 pre-req for python scripts (must also have their prereq python libraries installed)
    "module load R/3.6.1; export R_LIBS_USER=$HOME/local_R;", #Pre-requisite for CalculateTilingStatistic.R. Must also have installed prereq libraries (In this case in $HOME/local_R)
    "function CalculateTilingStatistic.R() {{ Rscript " + CalculateTilingStatistic_loc + " $@ ; }} ;"
]

shell.prefix("".join(software_strings))


# Helper Functions

def expt_df_json(expt_name, expt_dict, basepath, file_suffix):
    '''
    Creates json string to load information from config['expt_libs']
    as a dataframe for input into counts_to_results.py
    '''
    rows = []
    #Gather rows of data
    for timepoint in expt_dict:
        for rep in expt_dict[timepoint]:
            lib_id = expt_dict[timepoint][rep]
            file = os.path.join(basepath, lib_id + file_suffix)
            sr = pd.Series((expt_name, timepoint, rep, file))
            rows.append(sr)
    #Create pandas df
    df = pd.concat(rows, axis=1, ignore_index=True).transpose()
    df.columns = ['expt_name', 'timepoint', 'replicate', 'countsfilepath']
    #Convert to json
    jstring = df.to_json()
    #TODO: pandas to_json method includes escape characters from the use of the ujson module under the hood. If this changes in the future, can remove re.sub step.
    jstring_noescape = re.sub(r'\\/', '/', jstring)
    return(jstring_noescape)

def expt_get_libs(libdict):
    for time in libdict:
        for rep in libdict[time]:
            lib = libdict[time][rep]
            yield lib


# Set workdir - If running on Flux cluster, logs will be placed in this location
workdir:
    config['flux_log_dir']


# Rules

rule all:
    input:
        expand(os.path.join(RESULTS_DIR, "{expt}_{region}.preNormFilt.bedgraph"), expt=config['expt_libs'].keys(), region=config['tiling_region_beds'].keys()),
        expand(os.path.join(RESULTS_DIR, "{expt}_preNormFilt.9col.bed"), expt=config['expt_libs'].keys()),
        expand(os.path.join(RESULTS_DIR, "{expt}_sig_windows.bed"), expt=config['expt_libs'].keys()),
        expand(os.path.join(RESULTS_DIR, "{expt}_{region}.filt.norm.bedgraph"), expt=config['expt_libs'].keys(), region=config['tiling_region_beds'].keys()),
        expand(os.path.join(RESULTS_DIR, "{expt}_preFilt.norm.9col.bed"), expt=config['expt_libs'].keys()), #change from "{expt}_preFilt.norm.9col.bed"
        expand(os.path.join(RESULTS_DIR, "{expt}_filt.norm.9col.bed"), expt=config['expt_libs'].keys())


rule cutadapt:
    input:
        lambda wildcards: config['lib_filepath'][wildcards.library]
    output:
        temp(os.path.join(FASTQ_DIR, "{library}_trimmed.fastq.gz"))
    params:
        params = config['cutadapt_params']
    shell:
        "cutadapt {params.params} -o {output} {input}"

rule bowtie:
    input:
        os.path.join(FASTQ_DIR, "{library}_trimmed.fastq.gz")
        #If trimming is not needed, comment-out cutadapt rule and use line below for input to start pipeline from here
        #lambda wildcards: config['lib_filepath'][wildcards.library]
    output:
        temp(os.path.join(SAM_DIR, "{library}.sam"))
    threads: 8
    params:
        index = config['bowtie_index']
    shell:
        "zcat {input} | bowtie -v 0 --norc -p {threads} {params.index} - {output}"

rule count:
    input:
        os.path.join(SAM_DIR, "{library}.sam")
    output:
        os.path.join(COUNTS_DIR, "{library}.counts")
    run:
        counts = defaultdict(int)
        with open(input[0], "r") as in_file:
            for line in in_file:
                linedata = line.split("\t")
                item = linedata[2]
                counts[item] += 1
        with open(output[0], "w") as out_file:
            for key,value in counts.items():
                printstr = key + '\t' + str(value) + '\n'
                out_file.write(printstr)

rule counts_to_results:
    input:
        #Pseudo-inputs so that snakemake can keep track. The script actually takes input information as json string, so params.input_json is where the magic happens.
        lambda wildcards: expand(os.path.join(COUNTS_DIR, "{library}.counts"), library=expt_get_libs(config['expt_libs'][wildcards.expt]))
    output:
        os.path.join(RESULTS_DIR, "{expt}_results.txt")
    params:
        params = config['counts_to_results_params'],
        outdir = RESULTS_DIR,
        input_json = lambda wildcards: expt_df_json(wildcards.expt, config['expt_libs'][wildcards.expt], COUNTS_DIR, ".counts")
    shell:
        "python {SCRIPTS_DIR}/CRISPRi_counts_to_results.py {params.params} -o {params.outdir} -j '{params.input_json}'"

rule tiling_statistic:
    input:
        os.path.join(RESULTS_DIR, "{expt}_results.txt")
    output:
        os.path.join(RESULTS_DIR, "{expt}_results.norm.txt"),
        os.path.join(RESULTS_DIR, "{expt}_results.filt.norm.txt"),
        os.path.join(RESULTS_DIR, "{expt}_tiling_stat.txt")
    params:
        of_prefix = os.path.join(RESULTS_DIR, "{expt}"),
        params = config['tiling_statistic_params']
    shell:
        "CalculateTilingStatistic.R --input {input} --output {params.of_prefix} {params.params}"

rule significant_windows:
    input:
        os.path.join(RESULTS_DIR, "{expt}_tiling_stat.txt")
    output:
        os.path.join(RESULTS_DIR, "{expt}_sig_windows.bed")
    params:
        sig_col = config['sig_window_col'],
        sig_thres = float(config['sig_window_thres'])
    run:
        dat = pd.read_csv(input[0], sep="\t", dtype={"start" : pd.Int64Dtype(), "end" : pd.Int64Dtype()})
        sig = dat[dat[params.sig_col] <= params.sig_thres]
        sig['name'] = "."
        sig['strand'] = "."
        windows = sig[['chr', 'start', 'end', 'name', params.sig_col, 'strand']].copy() #Note: includes sig_col as the bed file score
        windows.to_csv(output[0], sep='\t', header=False, index=False)

rule bedgraph_rolling_means:
    #This produces a bedgraph with the unfiltered reads and no normalization
    input:
        os.path.join(RESULTS_DIR, "{expt}_results.txt")
    output:
        os.path.join(RESULTS_DIR, "{expt}_{region}.preNormFilt.bedgraph")
    params:
        bed_file = lambda wildcards: config['tiling_region_beds'][wildcards.region],
        params = config['bedgraph_rolling_means_params']
    shell:
        "python {SCRIPTS_DIR}/CRISPRi_bedgraph_rolling_means.py {params.params} -b {params.bed_file} -r {input} -o {output}"

rule bedgraph_rolling_means_filt_norm:
    #This produces a bedgraph using only the reads that passed the specified quality filters, normalized to controls as specified in paramaters.
    input:
        os.path.join(RESULTS_DIR, "{expt}_results.filt.norm.txt")
    output:
        os.path.join(RESULTS_DIR, "{expt}_{region}.filt.norm.bedgraph")
    params:
        bed_file = lambda wildcards: config['tiling_region_beds'][wildcards.region],
        params = config['bedgraph_rolling_means_params']
    shell:
        "python {SCRIPTS_DIR}/CRISPRi_bedgraph_rolling_means_filt_norm.py {params.params} -b {params.bed_file} -r {input} -o {output}"

rule make_9col_bedfile:
    # This creates a browser-compatible color-coded .bed of the guides with color corresponding to score (no filtering or normalization)
    #Assign colors to scores, place in 9th column of 9-column bed file
    input:
        os.path.join(RESULTS_DIR, "{expt}_results.txt")
    output:
        os.path.join(RESULTS_DIR, "{expt}_preNormFilt.9col.bed")
    run:
        colors = ["#CA0020", "#F4A582", "#808080", "#92C5DE", "#0571B0"] #Ordered from red to grey to blue
        #Use pandas Int64 for integer coordinates allowing for NA values
        #https://pandas.pydata.org/pandas-docs/version/0.24/whatsnew/v0.24.0.html#optional-integer-na-support
        dat = pd.read_csv(input[0], sep="\t", dtype={"start" : pd.Int64Dtype(), "end" : pd.Int64Dtype()})
        minscore = dat['mean_log2FC'].min()
        maxscore = dat['mean_log2FC'].max()
        #
        #Workaround for when minscore / maxscore are within intended bins of -2, -1, 1, 2
        if maxscore <= 2:
            maxscore = 2.5
        if minscore >= -2:
            minscore = -2.5
        #
        #Assign color bins
        bin_rgb = pd.cut(dat['mean_log2FC'], bins=[minscore,-2,-1,1,2,maxscore], labels = colors).rename("RGB", inplace=True)
        dat = dat.join(bin_rgb)
        dat['thickStart'] = dat['start']
        dat['thickEnd'] = dat['end']
        bed_9col = dat[['chr', 'start', 'end', 'OligoID', 'mean_log2FC', 'strand', 'thickStart', 'thickEnd', 'RGB']].copy()
        bed_9col.dropna(inplace=True)
        bed_9col.to_csv(output[0], sep='\t', header=False, index=False)

rule make_9col_bedfile_norm:
    # Color-coded .bed of the normalized guides with normalization but no filtering
    #Assign colors to scores, place in 9th column of 9-column bed file
    input:
        os.path.join(RESULTS_DIR, "{expt}_results.norm.txt")
    output:
        os.path.join(RESULTS_DIR, "{expt}_preFilt.norm.9col.bed")
    run:
        colors = ["#CA0020", "#F4A582", "#808080", "#92C5DE", "#0571B0"] #Ordered from red to grey to blue
        #Use pandas Int64 for integer coordinates allowing for NA values
        #https://pandas.pydata.org/pandas-docs/version/0.24/whatsnew/v0.24.0.html#optional-integer-na-support
        dat = pd.read_csv(input[0], sep="\t", dtype={"start" : pd.Int64Dtype(), "end" : pd.Int64Dtype()})
        minscore = dat['mean_log2FC_norm'].min() # temp change from 'mean_log2FC_norm'
        maxscore = dat['mean_log2FC_norm'].max() # temp change from 'mean_log2FC_norm'
        #
        #Workaround for when minscore / maxscore are within intended bins of -2, -1, 1, 2
        if maxscore <= 2:
            maxscore = 2.5
        if minscore >= -2:
            minscore = -2.5
        #
        #Assign color bins
        bin_rgb = pd.cut(dat['mean_log2FC_norm'], bins=[minscore,-2,-1,1,2,maxscore], labels = colors).rename("RGB", inplace=True)
        dat = dat.join(bin_rgb)
        dat['thickStart'] = dat['start']
        dat['thickEnd'] = dat['end']
        bed_9col = dat[['chr', 'start', 'end', 'OligoID', 'mean_log2FC_norm', 'strand', 'thickStart', 'thickEnd', 'RGB']].copy()
        bed_9col.dropna(inplace=True)
        bed_9col.to_csv(output[0], sep='\t', header=False, index=False)

rule make_9col_bedfile_filt_norm:
    # Color-coded .bed of the normalized guides with normalization and filtering for quality
    #Assign colors to scores, place in 9th column of 9-column bed file
    input:
        os.path.join(RESULTS_DIR, "{expt}_results.filt.norm.txt")
    output:
        os.path.join(RESULTS_DIR, "{expt}_filt.norm.9col.bed")
    run:
        colors = ["#CA0020", "#F4A582", "#808080", "#92C5DE", "#0571B0"] #Ordered from red to grey to blue
        #Use pandas Int64 for integer coordinates allowing for NA values
        #https://pandas.pydata.org/pandas-docs/version/0.24/whatsnew/v0.24.0.html#optional-integer-na-support
        dat = pd.read_csv(input[0], sep="\t", dtype={"start" : pd.Int64Dtype(), "end" : pd.Int64Dtype()})
        minscore = dat['mean_log2FC_norm'].min()
        maxscore = dat['mean_log2FC_norm'].max()
    #
    #Workaround for when minscore / maxscore are within intended bins of -2, -1, 1, 2
        if maxscore <= 2:
            maxscore = 2.5
        if minscore >= -2:
            minscore = -2.5
    #
    #Assign color bins
        bin_rgb = pd.cut(dat['mean_log2FC_norm'], bins=[minscore, -2,-1,1,2,maxscore], labels = colors).rename("RGB", inplace=True)
        dat = dat.join(bin_rgb)
        dat['thickStart'] = dat['start']
        dat['thickEnd'] = dat['end']
        bed_9col = dat[['chr', 'start', 'end', 'OligoID', 'mean_log2FC_norm', 'strand', 'thickStart', 'thickEnd', 'RGB']].copy()
        bed_9col.dropna(inplace=True)
        bed_9col.to_csv(output[0], sep='\t', header=False, index=False)
